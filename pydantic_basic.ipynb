{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Why Use Pydantic for LLM and GenAI?\n",
        "When working with LLMs, we deal with unstructured data (e.g., text responses, JSON API calls). Pydantic helps by:\n",
        "\n",
        "Validating API Requests & Responses – Ensures that input and output conform to a structured format.\n",
        "Defining Typed Data Models – Helps define clear schemas for prompts, completions, and metadata.\n",
        "Ensuring Consistency in AI Pipelines – Reduces errors in data exchange between LLMs and downstream applications.\n",
        "Efficient Parsing & Serialization – Converts between Python objects and JSON efficiently.\n"
      ],
      "metadata": {
        "id": "WCvJyoyRclzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VaPC5fAakL2i"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class get_data(BaseModel):\n",
        "  name: str\n",
        "  age: int\n",
        "  gender: str"
      ],
      "metadata": {
        "id": "Ebw7sK86lFVp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"name\": \"Prakash\", \"age\": 30, \"gender\": \"m\"}"
      ],
      "metadata": {
        "id": "YNIHEWddlNSI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = get_data(**data)"
      ],
      "metadata": {
        "id": "9-6lZqQalb_w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user"
      ],
      "metadata": {
        "id": "0AxVNxxIljig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41b994d-c578-414f-b773-fb694ee0f4ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "get_data(name='Prakash', age=30, gender='m')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user.name"
      ],
      "metadata": {
        "id": "94Mr6acLltYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b45bf318-13f0-44fc-d647-120a9c4e1be3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prakash'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(user)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar5za-islV8h",
        "outputId": "13def25d-554e-4e3c-ca23-388fd1d217f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='Prakash' age=30 gender='m'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using Pydantic in LLM and **GenAI**"
      ],
      "metadata": {
        "id": "N8kqEvhsZhzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TPOS-5Jzada2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1: Validating LLM Requests\n",
        "When sending prompts to an LLM, ensure they meet required constraints."
      ],
      "metadata": {
        "id": "Y4yTPWCZZpGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "kCQ9bI6MZeon"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMRequest(BaseModel):\n",
        "    prompt: str = Field(..., min_length=5, description=\"Input text for the model\")\n",
        "    max_tokens: int = Field(..., ge=10, le=500, description=\"Limit response length\")"
      ],
      "metadata": {
        "id": "4ns2zoWTZ2Xm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data={\"prompt\": \"What is LLM?\", \"max_tokens\": \"100\"}"
      ],
      "metadata": {
        "id": "ogQxnfW0Z5xH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLMRequest(**data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJfelBOxZ-91",
        "outputId": "267b09fa-0709-4b01-9a7f-305c5f666f45"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMRequest(prompt='What is LLM?', max_tokens=100)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2: Parsing LLM Responses"
      ],
      "metadata": {
        "id": "7GBo1vO2aYo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After getting a response from an LLM API, validate the output before using it."
      ],
      "metadata": {
        "id": "EyalvRDWajs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "id": "2e46r29EaYHd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMResponse(BaseModel):\n",
        "    text: str\n",
        "    model: str\n",
        "    token_usage: int"
      ],
      "metadata": {
        "id": "exCbqRgEanaV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated response from an LLM API\n",
        "api_response = {\"text\": \"Hello, how can I help you?\", \"model\": \"gpt-4\", \"token_usage\": 32}\n",
        "parsed_response = LLMResponse(**api_response)\n",
        "print(parsed_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVkQYtxKaoSN",
        "outputId": "64d10716-4541-4aad-ba4b-d98fe51d45ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Hello, how can I help you?' model='gpt-4' token_usage=32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using Pydantic with Generative AI Pipelines"
      ],
      "metadata": {
        "id": "tWIax4nUa5hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n"
      ],
      "metadata": {
        "id": "Q4CxWAANa7S9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Document(BaseModel):\n",
        "  title: str\n",
        "  content: str"
      ],
      "metadata": {
        "id": "Mfxwfx8lbuaU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummarizationRequest(BaseModel):\n",
        "  documents: List[Document]\n",
        "  summary_length: int"
      ],
      "metadata": {
        "id": "vQ7iUsrRbE9d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6muJRHSUbHcM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"documents\": [\n",
        "        {\"title\": \"AI\", \"content\": \"Artificial Intelligence is transforming industries.\"},\n",
        "        {\"title\": \"ML\", \"content\": \"Machine learning is a subset of AI focused on algorithms.\"}\n",
        "    ],\n",
        "    \"summary_length\": 50\n",
        "}\n"
      ],
      "metadata": {
        "id": "29x0QvNDbSdF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_request = SummarizationRequest(**data)\n",
        "print(summary_request)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT8OQd2Zb3BT",
        "outputId": "fd8ea0d4-195e-43ca-89dd-13bb9b749e18"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents=[Document(title='AI', content='Artificial Intelligence is transforming industries.'), Document(title='ML', content='Machine learning is a subset of AI focused on algorithms.')] summary_length=50\n"
          ]
        }
      ]
    }
  ]
}